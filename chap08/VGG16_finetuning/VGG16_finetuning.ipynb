{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメーターの値をセット\n",
    "num_train = 2000              # 訓練データの画像数\n",
    "num_validation = 800          # テストデータの画像数\n",
    "img_w, img_h = 150, 150       # 画像のサイズ\n",
    "channels = 3                  # チャンネル数\n",
    "batch_size = 20               # ミニバッチのサイズ\n",
    "train_data_dir = 'data/train' # 訓練データのフォルダー\n",
    "validation_data_dir = 'data/validation' # テストデータのフォルダー\n",
    "epochs = 100                  # 学習回数\n",
    "weight_file = 'weight.h5'     # 学習済みウェイトのファイル名\n",
    "result_dir = 'results'        # ファインチューニングにより学習した\n",
    "                              # ウェイトを保存するフォルダー名\n",
    "\n",
    "# resultsフォルダーが存在しなければ作成\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16モデルのサマリ\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "凍結後のサマリ\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "結合後のサマリ\n"
     ]
    }
   ],
   "source": [
    "## VGG16モデルと学習済み重みを読み込む\n",
    "vgg16_model = VGG16(include_top=False,        # 全結合層は層（FC）は読み込まない\n",
    "                    weights='imagenet',       # ImageNetで学習した重みを利用\n",
    "                    input_shape=(img_h, img_w, channels) # 入力データの形状\n",
    "                   )\n",
    "# VGG16モデルのサマリを出力\n",
    "print('VGG16モデルのサマリ')\n",
    "vgg16_model.summary()\n",
    "\n",
    "# VGG16のblock1_conv1からblock4_poolまでを凍結\n",
    "# block5のみを学習可能にする\n",
    "vgg16_model.trainable = True\n",
    "set_trainable = False\n",
    "for layer in vgg16_model.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:        \n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    \n",
    "## 凍結後のサマリを出力\n",
    "print('凍結後のサマリ')\n",
    "vgg16_model.summary()\n",
    "\n",
    "## VGG16モデルと独自のFC層を連結した計算モデルを構築\n",
    "# Sequentialオブジェクトを生成\n",
    "model = Sequential()\n",
    "\n",
    "# VGG16モデルを追加\n",
    "model.add(vgg16_model)\n",
    "# Flatten層\n",
    "model.add(Flatten())\n",
    "# 全結合層\n",
    "model.add(Dense(256,                 # ニューロン数は256\n",
    "                activation='relu'    # 活性化関数はReLU\n",
    "                ))\n",
    "# 出力層\n",
    "model.add(Dense(1,                   # ニューロン数は1\n",
    "                activation='sigmoid' # 活性化関数はシグモイド関数\n",
    "                ))\n",
    "\n",
    "# VGG16に独自のFC層を結合したモデルのサマリを出力\n",
    "print('結合後のサマリ')\n",
    "model.summary()\n",
    "\n",
    "## モデルのコンパイル\n",
    "# 最適化はRMSpropで行う\n",
    "# 学習率を小さくしたのはファインチューニングを\n",
    "# 行う層における変更の大きさを制限するため\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## 訓練データを読み込むジェネレーターを生成\n",
    "# データ拡張を行う\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,      # 40度の範囲でランダムに回転させる\n",
    "    width_shift_range=0.2,  # 横サイズの0.2の割合でランダムに水平移動\n",
    "    height_shift_range=0.2, # 縦サイズの0.2の割合でランダムに垂直移動\n",
    "    horizontal_flip=True,   # 水平方向にランダムに反転、左右の入れ替え\n",
    "    zoom_range=0.2,         # ランダムに拡大\n",
    "    shear_range=0.2         # シアー変換をかける\n",
    ")\n",
    "\n",
    "# Dog vs Catの訓練データを生成するするジェネレーター\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,             # 訓練データのフォルダー\n",
    "    target_size=(img_h, img_w), # 画像をリサイズ\n",
    "    batch_size=batch_size,      # ミニバッチのサイズ\n",
    "    class_mode='binary'         # 出力層は二値のラベルが必要\n",
    ")\n",
    "\n",
    "## テストデータを読み込むジェネレーターを生成\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Dog vs Catのテストデータを生成するするジェネレーター\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,        # テストデータのフォルダー\n",
    "    target_size=(img_h, img_w), # 画像をリサイズ\n",
    "    batch_size=batch_size,      # ミニバッチのサイズ\n",
    "    class_mode='binary'         # 出力層は二値のラベルが必要\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "40\n",
      "40\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 613s 6s/step - loss: 0.5372 - acc: 0.7430 - val_loss: 0.3292 - val_acc: 0.8625\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 613s 6s/step - loss: 0.3649 - acc: 0.8425 - val_loss: 0.2398 - val_acc: 0.8925\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 614s 6s/step - loss: 0.3107 - acc: 0.8640 - val_loss: 0.2166 - val_acc: 0.9075\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 614s 6s/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.1960 - val_acc: 0.9112\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 618s 6s/step - loss: 0.2606 - acc: 0.8920 - val_loss: 0.1902 - val_acc: 0.9087\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 0.2460 - acc: 0.8995 - val_loss: 0.1998 - val_acc: 0.9112\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 0.2273 - acc: 0.9040 - val_loss: 0.1806 - val_acc: 0.9312\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 653s 7s/step - loss: 0.2084 - acc: 0.9125 - val_loss: 0.1824 - val_acc: 0.9287\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 655s 7s/step - loss: 0.2168 - acc: 0.9105 - val_loss: 0.1822 - val_acc: 0.9275\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 657s 7s/step - loss: 0.1993 - acc: 0.9155 - val_loss: 0.1612 - val_acc: 0.9362\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 664s 7s/step - loss: 0.2010 - acc: 0.9215 - val_loss: 0.1536 - val_acc: 0.9350\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 755s 8s/step - loss: 0.1829 - acc: 0.9180 - val_loss: 0.1550 - val_acc: 0.9375\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 742s 7s/step - loss: 0.1754 - acc: 0.9320 - val_loss: 0.1536 - val_acc: 0.9362\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 737s 7s/step - loss: 0.1675 - acc: 0.9320 - val_loss: 0.1584 - val_acc: 0.9312\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 735s 7s/step - loss: 0.1667 - acc: 0.9240 - val_loss: 0.1613 - val_acc: 0.9312\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 762s 8s/step - loss: 0.1619 - acc: 0.9420 - val_loss: 0.1644 - val_acc: 0.9325\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 977s 10s/step - loss: 0.1402 - acc: 0.9450 - val_loss: 0.1502 - val_acc: 0.9437\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 905s 9s/step - loss: 0.1477 - acc: 0.9395 - val_loss: 0.1524 - val_acc: 0.9412\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 914s 9s/step - loss: 0.1469 - acc: 0.9355 - val_loss: 0.1511 - val_acc: 0.9375\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 947s 9s/step - loss: 0.1450 - acc: 0.9405 - val_loss: 0.1457 - val_acc: 0.9387\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 901s 9s/step - loss: 0.1310 - acc: 0.9460 - val_loss: 0.2010 - val_acc: 0.9212\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 908s 9s/step - loss: 0.1288 - acc: 0.9525 - val_loss: 0.1566 - val_acc: 0.9362\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 902s 9s/step - loss: 0.1204 - acc: 0.9490 - val_loss: 0.1748 - val_acc: 0.9362\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 941s 9s/step - loss: 0.1387 - acc: 0.9465 - val_loss: 0.1640 - val_acc: 0.9362\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 932s 9s/step - loss: 0.1103 - acc: 0.9500 - val_loss: 0.1425 - val_acc: 0.9437\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 908s 9s/step - loss: 0.1089 - acc: 0.9595 - val_loss: 0.1466 - val_acc: 0.9375\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 901s 9s/step - loss: 0.1200 - acc: 0.9495 - val_loss: 0.1393 - val_acc: 0.9387\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 949s 9s/step - loss: 0.1110 - acc: 0.9590 - val_loss: 0.1449 - val_acc: 0.9462\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 903s 9s/step - loss: 0.1059 - acc: 0.9575 - val_loss: 0.1496 - val_acc: 0.9437\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 915s 9s/step - loss: 0.1041 - acc: 0.9595 - val_loss: 0.1581 - val_acc: 0.9350\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 910s 9s/step - loss: 0.0895 - acc: 0.9650 - val_loss: 0.1616 - val_acc: 0.9437\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 953s 10s/step - loss: 0.0942 - acc: 0.9615 - val_loss: 0.1819 - val_acc: 0.9375\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 912s 9s/step - loss: 0.1051 - acc: 0.9555 - val_loss: 0.1608 - val_acc: 0.9425\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 914s 9s/step - loss: 0.0883 - acc: 0.9660 - val_loss: 0.1748 - val_acc: 0.9375\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 911s 9s/step - loss: 0.0944 - acc: 0.9630 - val_loss: 0.1602 - val_acc: 0.9425\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 970s 10s/step - loss: 0.0950 - acc: 0.9625 - val_loss: 0.1643 - val_acc: 0.9362\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 915s 9s/step - loss: 0.0719 - acc: 0.9715 - val_loss: 0.1611 - val_acc: 0.9387\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 912s 9s/step - loss: 0.0797 - acc: 0.9670 - val_loss: 0.1520 - val_acc: 0.9375\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 920s 9s/step - loss: 0.0748 - acc: 0.9720 - val_loss: 0.1649 - val_acc: 0.9400\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 948s 9s/step - loss: 0.0792 - acc: 0.9700 - val_loss: 0.1813 - val_acc: 0.9450\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 910s 9s/step - loss: 0.0730 - acc: 0.9740 - val_loss: 0.1516 - val_acc: 0.9437\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 897s 9s/step - loss: 0.0735 - acc: 0.9675 - val_loss: 0.2049 - val_acc: 0.9375\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 903s 9s/step - loss: 0.0577 - acc: 0.9790 - val_loss: 0.1611 - val_acc: 0.9462\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 943s 9s/step - loss: 0.0708 - acc: 0.9720 - val_loss: 0.1921 - val_acc: 0.9425\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 874s 9s/step - loss: 0.0533 - acc: 0.9775 - val_loss: 0.1905 - val_acc: 0.9425\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0690 - acc: 0.9770 - val_loss: 0.2316 - val_acc: 0.9300\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 860s 9s/step - loss: 0.0656 - acc: 0.9740 - val_loss: 0.1659 - val_acc: 0.9375\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 892s 9s/step - loss: 0.0669 - acc: 0.9750 - val_loss: 0.2323 - val_acc: 0.9287\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 866s 9s/step - loss: 0.0660 - acc: 0.9740 - val_loss: 0.2922 - val_acc: 0.9162\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 863s 9s/step - loss: 0.0604 - acc: 0.9785 - val_loss: 0.2532 - val_acc: 0.9325\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0651 - acc: 0.9760 - val_loss: 0.4666 - val_acc: 0.9025\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 913s 9s/step - loss: 0.0623 - acc: 0.9810 - val_loss: 0.1856 - val_acc: 0.9425\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 862s 9s/step - loss: 0.0532 - acc: 0.9785 - val_loss: 0.2098 - val_acc: 0.9300\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0619 - acc: 0.9780 - val_loss: 0.2067 - val_acc: 0.9425\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0566 - acc: 0.9800 - val_loss: 0.2174 - val_acc: 0.9325\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 899s 9s/step - loss: 0.0592 - acc: 0.9800 - val_loss: 0.2000 - val_acc: 0.9437\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 865s 9s/step - loss: 0.0508 - acc: 0.9810 - val_loss: 0.1654 - val_acc: 0.9462\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 867s 9s/step - loss: 0.0533 - acc: 0.9820 - val_loss: 0.2078 - val_acc: 0.9412\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 870s 9s/step - loss: 0.0570 - acc: 0.9775 - val_loss: 0.2720 - val_acc: 0.9300\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 918s 9s/step - loss: 0.0465 - acc: 0.9875 - val_loss: 0.3840 - val_acc: 0.9125\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 864s 9s/step - loss: 0.0419 - acc: 0.9845 - val_loss: 0.2010 - val_acc: 0.9437\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 862s 9s/step - loss: 0.0474 - acc: 0.9825 - val_loss: 0.2069 - val_acc: 0.9487\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0613 - acc: 0.9770 - val_loss: 0.3742 - val_acc: 0.9187\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 887s 9s/step - loss: 0.0459 - acc: 0.9845 - val_loss: 0.2269 - val_acc: 0.9462\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 869s 9s/step - loss: 0.0397 - acc: 0.9845 - val_loss: 0.1962 - val_acc: 0.9475\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 868s 9s/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.5888 - val_acc: 0.9012\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 863s 9s/step - loss: 0.0441 - acc: 0.9845 - val_loss: 0.2390 - val_acc: 0.9412\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 891s 9s/step - loss: 0.0491 - acc: 0.9795 - val_loss: 0.2217 - val_acc: 0.9425\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 876s 9s/step - loss: 0.0439 - acc: 0.9845 - val_loss: 0.2379 - val_acc: 0.9412\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 852s 9s/step - loss: 0.0479 - acc: 0.9805 - val_loss: 0.2098 - val_acc: 0.9400\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 851s 9s/step - loss: 0.0511 - acc: 0.9805 - val_loss: 0.2047 - val_acc: 0.9475\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 856s 9s/step - loss: 0.0369 - acc: 0.9855 - val_loss: 0.2508 - val_acc: 0.9387\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 884s 9s/step - loss: 0.0475 - acc: 0.9820 - val_loss: 0.2252 - val_acc: 0.9437\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 855s 9s/step - loss: 0.0417 - acc: 0.9855 - val_loss: 0.2408 - val_acc: 0.9387\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 852s 9s/step - loss: 0.0522 - acc: 0.9810 - val_loss: 0.2147 - val_acc: 0.9450\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 852s 9s/step - loss: 0.0373 - acc: 0.9870 - val_loss: 0.2824 - val_acc: 0.9325\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 904s 9s/step - loss: 0.0374 - acc: 0.9840 - val_loss: 0.2194 - val_acc: 0.9450\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 862s 9s/step - loss: 0.0311 - acc: 0.9865 - val_loss: 0.2455 - val_acc: 0.9425\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 861s 9s/step - loss: 0.0386 - acc: 0.9855 - val_loss: 0.3350 - val_acc: 0.9237\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 860s 9s/step - loss: 0.0351 - acc: 0.9865 - val_loss: 0.1934 - val_acc: 0.9500\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 905s 9s/step - loss: 0.0364 - acc: 0.9915 - val_loss: 0.1981 - val_acc: 0.9487\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 856s 9s/step - loss: 0.0408 - acc: 0.9845 - val_loss: 0.2505 - val_acc: 0.9475\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 852s 9s/step - loss: 0.0404 - acc: 0.9860 - val_loss: 0.3842 - val_acc: 0.9287\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 854s 9s/step - loss: 0.0327 - acc: 0.9895 - val_loss: 0.3154 - val_acc: 0.9375\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 890s 9s/step - loss: 0.0343 - acc: 0.9875 - val_loss: 0.1839 - val_acc: 0.9525\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 855s 9s/step - loss: 0.0297 - acc: 0.9890 - val_loss: 0.2132 - val_acc: 0.9525\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 860s 9s/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.2354 - val_acc: 0.9450\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 860s 9s/step - loss: 0.0433 - acc: 0.9845 - val_loss: 0.4391 - val_acc: 0.9112\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 910s 9s/step - loss: 0.0314 - acc: 0.9885 - val_loss: 0.3411 - val_acc: 0.9350\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 863s 9s/step - loss: 0.0388 - acc: 0.9880 - val_loss: 0.3005 - val_acc: 0.9287\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 857s 9s/step - loss: 0.0302 - acc: 0.9860 - val_loss: 0.3670 - val_acc: 0.9287\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 866s 9s/step - loss: 0.0445 - acc: 0.9825 - val_loss: 0.2660 - val_acc: 0.9437\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 844s 8s/step - loss: 0.0290 - acc: 0.9860 - val_loss: 0.2692 - val_acc: 0.9437\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 768s 8s/step - loss: 0.0243 - acc: 0.9940 - val_loss: 0.2901 - val_acc: 0.9400\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 843s 8s/step - loss: 0.0331 - acc: 0.9880 - val_loss: 0.2924 - val_acc: 0.9337\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 838s 8s/step - loss: 0.0318 - acc: 0.9885 - val_loss: 0.2527 - val_acc: 0.9450\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 829s 8s/step - loss: 0.0378 - acc: 0.9850 - val_loss: 0.3384 - val_acc: 0.9287\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 877s 9s/step - loss: 0.0378 - acc: 0.9870 - val_loss: 0.2293 - val_acc: 0.9425\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 839s 8s/step - loss: 0.0245 - acc: 0.9895 - val_loss: 0.3017 - val_acc: 0.9425\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 842s 8s/step - loss: 0.0317 - acc: 0.9860 - val_loss: 0.2471 - val_acc: 0.9475\n"
     ]
    }
   ],
   "source": [
    "## 学習を行う\n",
    "\n",
    "# 訓練データのジェネレーターのサイズ：63\n",
    "print(len(train_generator))\n",
    "# 訓練データの数をミニバッチのサイズで割った値：62\n",
    "print(num_train//batch_size)\n",
    "# テストデータのジェネレーターのサイズ：25\n",
    "print(len(validation_generator))\n",
    "# テストデータの数をミニバッチのサイズで割った値：25\n",
    "print(num_validation//batch_size)\n",
    "\n",
    "# モデルのファインチューニング\n",
    "history = model.fit_generator(\n",
    "    \n",
    "    # 訓練データのジェネレーター\n",
    "    generator=train_generator,\n",
    "    # 各エポックにおけるステップ数として\n",
    "    # 訓練データの数をミニバッチのサイズで割った値を指定\n",
    "    steps_per_epoch=num_train//batch_size,\n",
    "    # エポック数（学習回数）\n",
    "    epochs=epochs,\n",
    "    # テストデータのジェネレーター\n",
    "    validation_data=validation_generator,\n",
    "    # テストにおける各エポックにおけるステップ数として\n",
    "    # テストデータの数をミニバッチのサイズで割った値を指定\n",
    "    validation_steps=num_validation//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後のウェイトを保存する\n",
    "model.save_weights(os.path.join(result_dir, 'finetuning.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
