{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import tflearn.datasets.mnist as mnist\n",
    "\n",
    "# CNNの作成、学習に必要なライブラリのインポート\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNISTデータセットの読み込み(ラベルをone-hot表現に変換)\n",
    "x_trains, y_trains, x_tests, y_tests = mnist.load_data('data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 読み込み直後の各データの構造\n",
    "print(x_trains.shape) # (55000, 784)\n",
    "print(y_trains.shape) # (55000, 10)\n",
    "print(x_tests.shape)  # (10000, 784)\n",
    "print(y_tests.shape)  #  (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データの前処理\n",
    "\n",
    "# (55000,784)の2階テンソルを(None,28,28,1)の4階テンソルに変換\n",
    "x_trains = x_trains.reshape([-1, 28, 28, 1])\n",
    "# (10000, 784)の2階テンソルを10000×28×28×1の4階テンソルに変換\n",
    "x_tests = x_tests.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# データの前処理後の画像データの形状\n",
    "print(x_trains.shape) # (55000, 28, 28, 1)\n",
    "print(x_tests.shape)  # (10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 正解ラベルの一部を出力\n",
    "print(y_trains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toshiya\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\Toshiya\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# 畳み込みニューラルネットワーク\n",
    "\n",
    "# 初期化\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力層\n",
    "net = input_data(shape=[None, 28, 28, 1])\n",
    "\n",
    "# 畳み込み層1(ニューロン数：32)\n",
    "net = conv_2d(incoming=net,       # 直前の層を設定\n",
    "              nb_filter=32,       # フィルターの数\n",
    "              filter_size=(5, 5), # フィルターのサイズ\n",
    "              activation='relu'   # 活性化関数はReLU\n",
    "             )\n",
    "\n",
    "# 畳み込み層2(ニューロン数：64)\n",
    "net = conv_2d(incoming=net,       # 直前の層を設定\n",
    "              nb_filter=64,       # フィルターの数\n",
    "              filter_size=(5, 5), # フィルターのサイズ\n",
    "              activation='relu'   # 活性化関数はReLU\n",
    "             )\n",
    "\n",
    "# 全結合層(ニューロン数：128)\n",
    "net = fully_connected(incoming=net,    # 直前の層を設定 \n",
    "                      n_units=128,     # ニューロンの数\n",
    "                      activation='relu'# 活性化関数はReLU\n",
    "                     )\n",
    "\n",
    "# 出力層の作成(ニューロン数：10)\n",
    "net = fully_connected(incoming=net,\n",
    "                      n_units=10,\n",
    "                      activation='softmax'\n",
    "                      )\n",
    "\n",
    "# 学習条件の設定\n",
    "net = tflearn.regression(\n",
    "    incoming=net,                  # 対象のモデルを設定\n",
    "    optimizer='adam',              # 最適化の手法はAdam\n",
    "    learning_rate=0.001,           # 学習率\n",
    "    loss='categorical_crossentropy'# 誤差関数は交差エントロピー\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 13749  | total loss: \u001b[1m\u001b[32m0.21946\u001b[0m\u001b[0m | time: 396.147s\n",
      "| Adam | epoch: 010 | loss: 0.21946 - acc: 0.9880 -- iter: 43968/44000\n",
      "Training Step: 13750  | total loss: \u001b[1m\u001b[32m0.19774\u001b[0m\u001b[0m | time: 429.009s\n",
      "| Adam | epoch: 010 | loss: 0.19774 - acc: 0.9892 | val_loss: 0.06589 - val_acc: 0.9845 -- iter: 44000/44000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# 学習の実行\n",
    "model = tflearn.DNN(net)      # 作成したCNNと学習条件をセット\n",
    "model.fit(x_trains,           # 訓練データ(画像)\n",
    "          y_trains,           # 訓練データ(ラベル)\n",
    "          n_epoch=10,         # 学習回数\n",
    "          batch_size=32,      # ミニバッチのサイズ\n",
    "          validation_set=0.2, # 訓練データの20%をテストデータに使用\n",
    "          show_metric=True    # 各ステップごとに精度を出力\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
